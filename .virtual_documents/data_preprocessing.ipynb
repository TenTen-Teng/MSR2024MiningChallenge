


# Import libraries

import pandas as pd
import helper
import os
import pandas as pd
from langdetect import detect








# Set up file paths and target tables.
snapshots = ["snapshot_20230727"]
dir_path = "~/data/DevGPT/"

"""Change `target` to process other topics.

Options are "hn", "pr", "issue", "discussion", "commit", "file"
"""
# target = "TARGET"
target = "pr"
URL_rename = "URL_" + target

if target == "hn":
    pk = [URL_rename]
else:
    pk = [URL_rename, "RepoName"]


# Read all json file paths.
file_paths = []
for snapshot in snapshots:
    file_path = os.path.join(dir_path, snapshot)
    file_paths += helper.read_filepaths(file_path, target)


# Load Json files.
df = helper.load_dataframes(file_paths)

# Rename URL to URL_[target].
df.rename(columns={"URL": URL_rename}, inplace=True)
df.info()





records = []

pk += ["ChatgptSharing"]

for idx, row in df[pk].iterrows():
    for item in row["ChatgptSharing"]:
        obs = {}
        obs[URL_rename] = row[URL_rename]

        if target != "hn":
            obs["RepoName"] = row["RepoName"]
            
        obs.update(item)
        records.append(obs)

df_chatgpt_sharing = pd.DataFrame(records)

# Rename URL to URL_chatgptsharing.
df_chatgpt_sharing.rename(columns={"URL": "URL_chatgptsharing"}, inplace=True)
df_chatgpt_sharing.info()






records = []

pk.pop() 
pk += ["URL_chatgptsharing", "Mention"]

for idx, row in df_chatgpt_sharing[pk].iterrows():

    if not isinstance(row["Mention"], dict):
        continue

    obs = {}
    obs[URL_rename] = row[URL_rename]

    if target != "hn":
        obs["RepoName"] = row["RepoName"]
        
    obs["URL_chatgptsharing"] = row["URL_chatgptsharing"]
    obs.update(row["Mention"])
    records.append(obs)

df_mention = pd.DataFrame(records)
df_mention.info()





records = []

pk += ["Conversations"]
for idx, row in df_chatgpt_sharing[pk].iterrows():

    if not isinstance(row["Conversations"], list):
        continue

    for item in row["Conversations"]:
        obs = {}
        obs[URL_rename] = row[URL_rename]

        if target != "hn":
            obs["RepoName"] = row["RepoName"]
            
        obs["URL_chatgptsharing"] = row["URL_chatgptsharing"]
        obs.update(item)
        records.append(obs)

df_conversation = pd.DataFrame(records)
df_conversation.info()





# Remove redundant columns
df = df.drop(columns="ChatgptSharing")
df_chatgpt_sharing = df_chatgpt_sharing.drop(columns=["Mention", "Conversations"])





# # df dataframe contains the initial dataset
# df.to_csv(
#     os.path.join(dir_path, "cleaned", target + ".csv")
#     )

# # df_chatgpt_sharing dataframe contains chatgptsharing content in target table.
# # It can combine with other tables using URL_'target' and RepoName.
# df_chatgpt_sharing.to_csv(
#     os.path.join(dir_path, "cleaned", target + "_chatgpt_sharing.csv")
#     )

# # df_mention dataframe contains mention content in target table.
# # It can combine with other tables using URL_'target' and RepoName.
# df_mention.to_csv(
#     os.path.join(dir_path, "cleaned", target + "_mention.csv")
#     )

# # df_conversation dataframe contains conversation content in target table.
# # It can combine with other tables using URL_'target' and RepoName.
# df_conversation.to_csv(
#     os.path.join(dir_path, "cleaned", target + "_conversation.csv")
#     )





# Merge ChatGptSharing table to target table.
if target != "hn":
    merge_on = [URL_rename, "RepoName"]
else:
    merge_on = [URL_rename]

df_total = pd.merge(
    df, df_chatgpt_sharing,
    left_on=merge_on, 
    right_on=merge_on, 
    how="left"
)


# Merge Mention table to target table.
df_total = pd.merge(
    df_total, df_mention,
    left_on=merge_on, 
    right_on=merge_on, 
    how="left"
)


# Merge Conversation table to target table.
df_total = pd.merge(
    df_total, df_conversation,
    left_on=merge_on, 
    right_on=merge_on, 
    how="left"
)


df_total.columns


df_total.info()


# # Save to file.

# df_total.to_csv(os.path.join(dir_path, "cleaned", target + "_total.csv"))








# Read CSV files.
df_pr = pd.read_csv("~/data/DevGPT/cleaned/pr_total.csv")
df_issue = pd.read_csv("~/data/DevGPT/cleaned/issue_total.csv")
df_discussion = pd.read_csv("~/data/DevGPT/cleaned/discussion_total.csv")





# Clean them up
# Remove nan answer and promot.
df_pr = df_pr[~df_pr["Answer"].isna()]
df_pr = df_pr[~df_pr["Prompt"].isna()]

df_issue = df_issue[~df_issue["Answer"].isna()]
df_issue = df_issue[~df_issue["Prompt"].isna()]

df_discussion = df_discussion[~df_discussion["Answer"].isna()]
df_discussion = df_discussion[~df_discussion["Prompt"].isna()]





# Filter out Python and English
df_pr = df_pr.loc[df_pr["RepoLanguage"] == "Python"]
df_issue = df_issue.loc[df_issue["RepoLanguage"] == "Python"]
df_discussion = df_discussion.loc[df_discussion["RepoLanguage"] == "Python"]

# Detect answer language
df_pr["Language"] = df_pr["Answer"].apply(detect)
df_issue["Language"] = df_issue["Answer"].apply(detect)
df_discussion["Language"] = df_discussion["Answer"].apply(detect)

# Get English only.
df_pr = df_pr.loc[df_pr["Language"] == "en"]
df_issue = df_issue.loc[df_issue["Language"] == "en"]
df_discussion = df_discussion.loc[df_discussion["Language"] == "en"]

print(len(df_pr), len(df_issue), len(df_discussion))





# Unnest prompt and answer
df_pr2 = df_pr[["RepoName", "URL_chatgptsharing", "Prompt", "Answer"]].drop_duplicates()
df_pr3 = df_pr[["RepoName", "URL_chatgptsharing_x", "Prompt", "Answer"]].drop_duplicates()
df_pr3.rename(columns={"URL_chatgptsharing_x": "URL_chatgptsharing"}, inplace=True)
df_pr4 = df_pr[["RepoName", "URL_chatgptsharing_y", "Prompt", "Answer"]].drop_duplicates()
df_pr4.rename(columns={"URL_chatgptsharing_y": "URL_chatgptsharing"}, inplace=True)

df_issue2 = df_issue[["RepoName", "URL_chatgptsharing", "Prompt", "Answer"]].drop_duplicates()
df_issue3 = df_issue[["RepoName", "URL_chatgptsharing_x", "Prompt", "Answer"]].drop_duplicates()
df_issue3.rename(columns={"URL_chatgptsharing_x": "URL_chatgptsharing"}, inplace=True)
df_issue4 = df_issue[["RepoName", "URL_chatgptsharing_y", "Prompt", "Answer"]].drop_duplicates()
df_issue4.rename(columns={"URL_chatgptsharing_y": "URL_chatgptsharing"}, inplace=True)

df_discussion2 = df_discussion[["RepoName", "URL_chatgptsharing", "Prompt", "Answer"]].drop_duplicates()
df_discussion3 = df_discussion[["RepoName", "URL_chatgptsharing_x", "Prompt", "Answer"]].drop_duplicates()
df_discussion3.rename(columns={"URL_chatgptsharing_x": "URL_chatgptsharing"}, inplace=True)
df_discussion4 = df_discussion[["RepoName", "URL_chatgptsharing_y", "Prompt", "Answer"]].drop_duplicates()
df_discussion4.rename(columns={"URL_chatgptsharing_y": "URL_chatgptsharing"}, inplace=True)


print(len(df_pr2), len(df_pr3), len(df_pr4))
print(len(df_issue2), len(df_issue3), len(df_issue4))
print(len(df_discussion2), len(df_discussion3), len(df_discussion4))



# Concatenate final dataset.
df = pd.concat(
    [
        df_pr2, df_pr3, df_pr4, df_issue2, df_issue3, df_issue4, df_discussion2,
        df_discussion3, df_discussion4
        ]
    )
df.drop_duplicates()


df.info()





# # Save to file

# df.to_csv(os.path.join(dir_path, "cleaned", "combine.csv"))
