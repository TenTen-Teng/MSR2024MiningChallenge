{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Process dataset by topics such as `pull request`, `issue`, `discussion`, and so on.\n",
    "\n",
    "**Table of Content**\n",
    "- [Proprocessing Original DataFrame](#preprocessing-original-dataframe)\n",
    "  - [Convert JSON file to DataFrame](#convert-json-file-to-dataframe)\n",
    "  - [Extract ChatGPTSharing Table](#extract-chatgptsharing-table)\n",
    "  - [Extract Mention table](#extract-mention-table)\n",
    "  - [Extract Conversation Table](#extract-conversation-table)\n",
    "  - [Clean up](#clean-up)\n",
    "  - [Save to file](#save-to-file)\n",
    "  - [Combine to a big dataframe](#combine-to-a-big-dataframe)\n",
    "- [Merge Different Topics/JSON Files](#merge-different-topicsjson-files)\n",
    "  - [Read CSV files](#read-csv-files)\n",
    "  - [Remove Empty Answer and Prompt](#remove-empty-answer-and-prompt)\n",
    "  - [Filter out Python and English Prompt and Answer](#filter-out-python-and-english-prompt-and-answer)\n",
    "  - [Unnest Prompt/Answer and Concatenation.](#unnest-promptanswer-and-concatenation)\n",
    "  - [Save Merged Dataset to File](#save-merged-dataset-to-file)\n",
    "\n",
    "> NOTE\n",
    "> \n",
    "> 1. All `dataframe.to_csv()` codes are blocked. Feel free to unblock them when saving. \n",
    "> 2. All file paths to CSV files are replaced with relative paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import helper\n",
    "import os\n",
    "import pandas as pd\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Original DataFrame\n",
    "\n",
    "Filter data by `snapshot_20230727`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON file to DataFrame\n",
    "\n",
    "The following code iterates the local data directory to read the 'target' JSON file.\n",
    "\n",
    "To process a specific JSON file, change variable `target` to one of \"hn\", \"pr\", \"issue\", \"discussion\", \"commit\", \"file\" and run through: [Preprocessing Original DataFrame](#preprocessing-original-dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up file paths and target tables.\n",
    "snapshots = [\"snapshot_20230727\"]\n",
    "dir_path = \"~/data/DevGPT/\"\n",
    "\n",
    "\"\"\"Change `target` to process other topics.\n",
    "\n",
    "Options are \"hn\", \"pr\", \"issue\", \"discussion\", \"commit\", \"file\"\n",
    "\"\"\"\n",
    "# target = \"TARGET\"\n",
    "target = \"pr\"\n",
    "URL_rename = \"URL_\" + target\n",
    "\n",
    "if target == \"hn\":\n",
    "    pk = [URL_rename]\n",
    "else:\n",
    "    pk = [URL_rename, \"RepoName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all json file paths.\n",
    "file_paths = []\n",
    "for snapshot in snapshots:\n",
    "    file_path = os.path.join(dir_path, snapshot)\n",
    "    file_paths += helper.read_filepaths(file_path, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 147 entries, 0 to 146\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Type               147 non-null    object\n",
      " 1   URL_pr             147 non-null    object\n",
      " 2   Author             147 non-null    object\n",
      " 3   RepoName           147 non-null    object\n",
      " 4   RepoLanguage       144 non-null    object\n",
      " 5   Number             147 non-null    int64 \n",
      " 6   Title              147 non-null    object\n",
      " 7   Body               147 non-null    object\n",
      " 8   CreatedAt          147 non-null    object\n",
      " 9   ClosedAt           130 non-null    object\n",
      " 10  MergedAt           110 non-null    object\n",
      " 11  UpdatedAt          147 non-null    object\n",
      " 12  State              147 non-null    object\n",
      " 13  Additions          147 non-null    int64 \n",
      " 14  Deletions          147 non-null    int64 \n",
      " 15  ChangedFiles       147 non-null    int64 \n",
      " 16  CommitsTotalCount  147 non-null    int64 \n",
      " 17  CommitShas         96 non-null     object\n",
      " 18  ChatgptSharing     147 non-null    object\n",
      " 19  CommitSha          51 non-null     object\n",
      " 20  source_date        147 non-null    object\n",
      "dtypes: int64(5), object(16)\n",
      "memory usage: 24.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load Json files.\n",
    "df = helper.load_dataframes(file_paths)\n",
    "\n",
    "# Rename URL to URL_[target].\n",
    "df.rename(columns={\"URL\": URL_rename}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ChatGPTSharing Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   URL_pr              173 non-null    object \n",
      " 1   RepoName            173 non-null    object \n",
      " 2   URL_chatgptsharing  173 non-null    object \n",
      " 3   Mention             173 non-null    object \n",
      " 4   Status              173 non-null    int64  \n",
      " 5   DateOfConversation  160 non-null    object \n",
      " 6   DateOfAccess        160 non-null    object \n",
      " 7   Title               160 non-null    object \n",
      " 8   NumberOfPrompts     160 non-null    float64\n",
      " 9   TokensOfPrompts     160 non-null    float64\n",
      " 10  TokensOfAnswers     160 non-null    float64\n",
      " 11  Model               160 non-null    object \n",
      " 12  Conversations       160 non-null    object \n",
      " 13  HTMLContent         160 non-null    object \n",
      "dtypes: float64(3), int64(1), object(10)\n",
      "memory usage: 19.1+ KB\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "pk += [\"ChatgptSharing\"]\n",
    "\n",
    "for idx, row in df[pk].iterrows():\n",
    "    for item in row[\"ChatgptSharing\"]:\n",
    "        obs = {}\n",
    "        obs[URL_rename] = row[URL_rename]\n",
    "\n",
    "        if target != \"hn\":\n",
    "            obs[\"RepoName\"] = row[\"RepoName\"]\n",
    "            \n",
    "        obs.update(item)\n",
    "        records.append(obs)\n",
    "\n",
    "df_chatgpt_sharing = pd.DataFrame(records)\n",
    "\n",
    "# Rename URL to URL_chatgptsharing.\n",
    "df_chatgpt_sharing.rename(columns={\"URL\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "df_chatgpt_sharing.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Mention table\n",
    "\n",
    "`MentionedURL` is identical with `URL_[target]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173 entries, 0 to 172\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   URL_pr              173 non-null    object\n",
      " 1   RepoName            173 non-null    object\n",
      " 2   URL_chatgptsharing  173 non-null    object\n",
      " 3   MentionedURL        173 non-null    object\n",
      " 4   MentionedProperty   173 non-null    object\n",
      " 5   MentionedAuthor     173 non-null    object\n",
      " 6   MentionedText       173 non-null    object\n",
      " 7   MentionedPath       54 non-null     object\n",
      "dtypes: object(8)\n",
      "memory usage: 10.9+ KB\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "pk.pop() \n",
    "pk += [\"URL_chatgptsharing\", \"Mention\"]\n",
    "\n",
    "for idx, row in df_chatgpt_sharing[pk].iterrows():\n",
    "\n",
    "    if not isinstance(row[\"Mention\"], dict):\n",
    "        continue\n",
    "\n",
    "    obs = {}\n",
    "    obs[URL_rename] = row[URL_rename]\n",
    "\n",
    "    if target != \"hn\":\n",
    "        obs[\"RepoName\"] = row[\"RepoName\"]\n",
    "        \n",
    "    obs[\"URL_chatgptsharing\"] = row[\"URL_chatgptsharing\"]\n",
    "    obs.update(row[\"Mention\"])\n",
    "    records.append(obs)\n",
    "\n",
    "df_mention = pd.DataFrame(records)\n",
    "df_mention.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Conversation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 668 entries, 0 to 667\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   URL_pr              668 non-null    object\n",
      " 1   RepoName            668 non-null    object\n",
      " 2   URL_chatgptsharing  668 non-null    object\n",
      " 3   Prompt              668 non-null    object\n",
      " 4   Answer              668 non-null    object\n",
      " 5   ListOfCode          668 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "pk += [\"Conversations\"]\n",
    "for idx, row in df_chatgpt_sharing[pk].iterrows():\n",
    "\n",
    "    if not isinstance(row[\"Conversations\"], list):\n",
    "        continue\n",
    "\n",
    "    for item in row[\"Conversations\"]:\n",
    "        obs = {}\n",
    "        obs[URL_rename] = row[URL_rename]\n",
    "\n",
    "        if target != \"hn\":\n",
    "            obs[\"RepoName\"] = row[\"RepoName\"]\n",
    "            \n",
    "        obs[\"URL_chatgptsharing\"] = row[\"URL_chatgptsharing\"]\n",
    "        obs.update(item)\n",
    "        records.append(obs)\n",
    "\n",
    "df_conversation = pd.DataFrame(records)\n",
    "df_conversation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "4 tables: `df_[target]`, `df_chatgpt_sharing`, `df_mention`, `df_conversation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant columns\n",
    "df = df.drop(columns=\"ChatgptSharing\")\n",
    "df_chatgpt_sharing = df_chatgpt_sharing.drop(columns=[\"Mention\", \"Conversations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file\n",
    "\n",
    "> NOTE\n",
    ">\n",
    "> The default output path is the same as the input. Our outputs will be saved into\n",
    "> a new folder `cleaned`.\n",
    ">\n",
    "> Feel free to unblock the code to save a copy into your local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df dataframe contains the initial dataset\n",
    "# df.to_csv(\n",
    "#     os.path.join(dir_path, \"cleaned\", target + \".csv\")\n",
    "#     )\n",
    "\n",
    "# # df_chatgpt_sharing dataframe contains chatgptsharing content in target table.\n",
    "# # It can combine with other tables using URL_'target' and RepoName.\n",
    "# df_chatgpt_sharing.to_csv(\n",
    "#     os.path.join(dir_path, \"cleaned\", target + \"_chatgpt_sharing.csv\")\n",
    "#     )\n",
    "\n",
    "# # df_mention dataframe contains mention content in target table.\n",
    "# # It can combine with other tables using URL_'target' and RepoName.\n",
    "# df_mention.to_csv(\n",
    "#     os.path.join(dir_path, \"cleaned\", target + \"_mention.csv\")\n",
    "#     )\n",
    "\n",
    "# # df_conversation dataframe contains conversation content in target table.\n",
    "# # It can combine with other tables using URL_'target' and RepoName.\n",
    "# df_conversation.to_csv(\n",
    "#     os.path.join(dir_path, \"cleaned\", target + \"_conversation.csv\")\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine to a big dataframe\n",
    "\n",
    "`df_total` is the dataframe that contains all the information of the target table.\n",
    "Combining `chatgptsharing`, `mention`, and `conversation`\n",
    "\n",
    "> NOTE\n",
    ">\n",
    "> Combine data from multiple dates can be nasty, the dataframe will become too large to process or save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ChatGptSharing table to target table.\n",
    "if target != \"hn\":\n",
    "    merge_on = [URL_rename, \"RepoName\"]\n",
    "else:\n",
    "    merge_on = [URL_rename]\n",
    "\n",
    "df_total = pd.merge(\n",
    "    df, df_chatgpt_sharing,\n",
    "    left_on=merge_on, \n",
    "    right_on=merge_on, \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Mention table to target table.\n",
    "df_total = pd.merge(\n",
    "    df_total, df_mention,\n",
    "    left_on=merge_on, \n",
    "    right_on=merge_on, \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Conversation table to target table.\n",
    "df_total = pd.merge(\n",
    "    df_total, df_conversation,\n",
    "    left_on=merge_on, \n",
    "    right_on=merge_on, \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'URL_pr', 'Author', 'RepoName', 'RepoLanguage', 'Number',\n",
       "       'Title_x', 'Body', 'CreatedAt', 'ClosedAt', 'MergedAt', 'UpdatedAt',\n",
       "       'State', 'Additions', 'Deletions', 'ChangedFiles', 'CommitsTotalCount',\n",
       "       'CommitShas', 'CommitSha', 'source_date', 'URL_chatgptsharing_x',\n",
       "       'Status', 'DateOfConversation', 'DateOfAccess', 'Title_y',\n",
       "       'NumberOfPrompts', 'TokensOfPrompts', 'TokensOfAnswers', 'Model',\n",
       "       'HTMLContent', 'URL_chatgptsharing_y', 'MentionedURL',\n",
       "       'MentionedProperty', 'MentionedAuthor', 'MentionedText',\n",
       "       'MentionedPath', 'URL_chatgptsharing', 'Prompt', 'Answer',\n",
       "       'ListOfCode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1784 entries, 0 to 1783\n",
      "Data columns (total 40 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Type                  1784 non-null   object \n",
      " 1   URL_pr                1784 non-null   object \n",
      " 2   Author                1784 non-null   object \n",
      " 3   RepoName              1784 non-null   object \n",
      " 4   RepoLanguage          1778 non-null   object \n",
      " 5   Number                1784 non-null   int64  \n",
      " 6   Title_x               1784 non-null   object \n",
      " 7   Body                  1784 non-null   object \n",
      " 8   CreatedAt             1784 non-null   object \n",
      " 9   ClosedAt              1732 non-null   object \n",
      " 10  MergedAt              1460 non-null   object \n",
      " 11  UpdatedAt             1784 non-null   object \n",
      " 12  State                 1784 non-null   object \n",
      " 13  Additions             1784 non-null   int64  \n",
      " 14  Deletions             1784 non-null   int64  \n",
      " 15  ChangedFiles          1784 non-null   int64  \n",
      " 16  CommitsTotalCount     1784 non-null   int64  \n",
      " 17  CommitShas            1389 non-null   object \n",
      " 18  CommitSha             395 non-null    object \n",
      " 19  source_date           1784 non-null   object \n",
      " 20  URL_chatgptsharing_x  1784 non-null   object \n",
      " 21  Status                1784 non-null   int64  \n",
      " 22  DateOfConversation    1768 non-null   object \n",
      " 23  DateOfAccess          1768 non-null   object \n",
      " 24  Title_y               1768 non-null   object \n",
      " 25  NumberOfPrompts       1768 non-null   float64\n",
      " 26  TokensOfPrompts       1768 non-null   float64\n",
      " 27  TokensOfAnswers       1768 non-null   float64\n",
      " 28  Model                 1768 non-null   object \n",
      " 29  HTMLContent           1768 non-null   object \n",
      " 30  URL_chatgptsharing_y  1784 non-null   object \n",
      " 31  MentionedURL          1784 non-null   object \n",
      " 32  MentionedProperty     1784 non-null   object \n",
      " 33  MentionedAuthor       1784 non-null   object \n",
      " 34  MentionedText         1784 non-null   object \n",
      " 35  MentionedPath         232 non-null    object \n",
      " 36  URL_chatgptsharing    1770 non-null   object \n",
      " 37  Prompt                1770 non-null   object \n",
      " 38  Answer                1770 non-null   object \n",
      " 39  ListOfCode            1770 non-null   object \n",
      "dtypes: float64(3), int64(6), object(31)\n",
      "memory usage: 557.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to file.\n",
    "\n",
    "# df_total.to_csv(os.path.join(dir_path, \"cleaned\", target + \"_total.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Different Topics/JSON Files\n",
    "\n",
    "In this project, we analyze data from `pull requests`, `issues`, and `discussions`.\n",
    "\n",
    "To merge data from these different sources, we use the primary key `RepoName`, which is shared across all JSON files.\n",
    "\n",
    "The following code reads data from previously cleaned CSV files, filters repositories using the programming language `Python` and the communication language `English`, selects relevant columns, and merges them into a consolidated dataset. Finally, the processed data is saved locally for future analysis.\n",
    "\n",
    "In the end, we have 1321 rows and 4 columns in the merged dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files.\n",
    "df_pr = pd.read_csv(\"~/data/DevGPT/cleaned/pr_total.csv\")\n",
    "df_issue = pd.read_csv(\"~/data/DevGPT/cleaned/issue_total.csv\")\n",
    "df_discussion = pd.read_csv(\"~/data/DevGPT/cleaned/discussion_total.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Empty Answer and Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean them up\n",
    "# Remove nan answer and promot.\n",
    "df_pr = df_pr[~df_pr[\"Answer\"].isna()]\n",
    "df_pr = df_pr[~df_pr[\"Prompt\"].isna()]\n",
    "\n",
    "df_issue = df_issue[~df_issue[\"Answer\"].isna()]\n",
    "df_issue = df_issue[~df_issue[\"Prompt\"].isna()]\n",
    "\n",
    "df_discussion = df_discussion[~df_discussion[\"Answer\"].isna()]\n",
    "df_discussion = df_discussion[~df_discussion[\"Prompt\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out Python and English Prompt and Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 287 62\n"
     ]
    }
   ],
   "source": [
    "# Filter out Python and English\n",
    "df_pr = df_pr.loc[df_pr[\"RepoLanguage\"] == \"Python\"]\n",
    "df_issue = df_issue.loc[df_issue[\"RepoLanguage\"] == \"Python\"]\n",
    "df_discussion = df_discussion.loc[df_discussion[\"RepoLanguage\"] == \"Python\"]\n",
    "\n",
    "# Detect answer language\n",
    "df_pr[\"Language\"] = df_pr[\"Answer\"].apply(detect)\n",
    "df_issue[\"Language\"] = df_issue[\"Answer\"].apply(detect)\n",
    "df_discussion[\"Language\"] = df_discussion[\"Answer\"].apply(detect)\n",
    "\n",
    "# Get English only.\n",
    "df_pr = df_pr.loc[df_pr[\"Language\"] == \"en\"]\n",
    "df_issue = df_issue.loc[df_issue[\"Language\"] == \"en\"]\n",
    "df_discussion = df_discussion.loc[df_discussion[\"Language\"] == \"en\"]\n",
    "\n",
    "print(len(df_pr), len(df_issue), len(df_discussion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unnest Prompt/Answer and Concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 201 201\n",
      "204 204 218\n",
      "39 39 41\n"
     ]
    }
   ],
   "source": [
    "# Unnest prompt and answer\n",
    "df_pr2 = df_pr[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_pr3 = df_pr[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing_x\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_pr3.rename(columns={\"URL_chatgptsharing_x\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_pr4 = df_pr[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing_y\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_pr4.rename(columns={\"URL_chatgptsharing_y\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_issue2 = df_issue[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_issue3 = df_issue[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing_x\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_issue3.rename(columns={\"URL_chatgptsharing_x\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_issue4 = df_issue[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing_y\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_issue4.rename(columns={\"URL_chatgptsharing_y\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_discussion2 = df_discussion[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_discussion3 = df_discussion[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing_x\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_discussion3.rename(columns={\"URL_chatgptsharing_x\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_discussion4 = df_discussion[\n",
    "    [\n",
    "        \"RepoName\", \"URL_chatgptsharing_y\", \"Prompt\", \"Answer\", \"TokensOfPrompts\", \"TokensOfAnswers\"\n",
    "        ]\n",
    "    ].drop_duplicates()\n",
    "df_discussion4.rename(columns={\"URL_chatgptsharing_y\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "\n",
    "print(len(df_pr2), len(df_pr3), len(df_pr4))\n",
    "print(len(df_issue2), len(df_issue3), len(df_issue4))\n",
    "print(len(df_discussion2), len(df_discussion3), len(df_discussion4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RepoName</th>\n",
       "      <th>URL_chatgptsharing</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "      <th>TokensOfPrompts</th>\n",
       "      <th>TokensOfAnswers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>paul-gauthier/aider</td>\n",
       "      <td>https://chat.openai.com/share/4555f0ea-1e7b-49...</td>\n",
       "      <td>How can I setup a github action to automatical...</td>\n",
       "      <td>Sure, I can certainly help you with that. Here...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>paul-gauthier/aider</td>\n",
       "      <td>https://chat.openai.com/share/4555f0ea-1e7b-49...</td>\n",
       "      <td>How can I setup a github action to automatical...</td>\n",
       "      <td>Sure, I can certainly help you with that. Here...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>chitalian/gptask</td>\n",
       "      <td>https://chat.openai.com/share/902cd378-3ebc-4e...</td>\n",
       "      <td>Give me some test commands for this\\n\\nimport ...</td>\n",
       "      <td>This Python script is a command-line tool that...</td>\n",
       "      <td>980.0</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>how to get the first 20 rows from a django model?</td>\n",
       "      <td>To get the first 20 rows from a Django model, ...</td>\n",
       "      <td>340.0</td>\n",
       "      <td>941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>I have this view for infinite scroll, would be...</td>\n",
       "      <td>Certainly! You can refactor the code to use Dj...</td>\n",
       "      <td>340.0</td>\n",
       "      <td>941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>And more?</td>\n",
       "      <td>Certainly! Here are a few more options for a s...</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>And more?</td>\n",
       "      <td>Certainly! Here are a few more options for a s...</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>More.</td>\n",
       "      <td>Certainly! Here are a few more options for a s...</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>sugi-01096/72</td>\n",
       "      <td>https://chat.openai.com/share/e2c50f86-6c14-4f...</td>\n",
       "      <td>import streamlit as st\\nimport json\\n\\n\\ndef s...</td>\n",
       "      <td>The code you provided seems to be a simple bul...</td>\n",
       "      <td>785.0</td>\n",
       "      <td>3270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>sugi-01096/72</td>\n",
       "      <td>https://chat.openai.com/share/e2c50f86-6c14-4f...</td>\n",
       "      <td>import streamlit as st\\nimport json\\n\\n\\ndef s...</td>\n",
       "      <td>The code you provided seems to be a simple bul...</td>\n",
       "      <td>809.0</td>\n",
       "      <td>7233.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RepoName                                 URL_chatgptsharing  \\\n",
       "7870   paul-gauthier/aider  https://chat.openai.com/share/4555f0ea-1e7b-49...   \n",
       "7872   paul-gauthier/aider  https://chat.openai.com/share/4555f0ea-1e7b-49...   \n",
       "7898      chitalian/gptask  https://chat.openai.com/share/902cd378-3ebc-4e...   \n",
       "7906  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7907  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "...                    ...                                                ...   \n",
       "311       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "312       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "313       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "111          sugi-01096/72  https://chat.openai.com/share/e2c50f86-6c14-4f...   \n",
       "151          sugi-01096/72  https://chat.openai.com/share/e2c50f86-6c14-4f...   \n",
       "\n",
       "                                                 Prompt  \\\n",
       "7870  How can I setup a github action to automatical...   \n",
       "7872  How can I setup a github action to automatical...   \n",
       "7898  Give me some test commands for this\\n\\nimport ...   \n",
       "7906  how to get the first 20 rows from a django model?   \n",
       "7907  I have this view for infinite scroll, would be...   \n",
       "...                                                 ...   \n",
       "311                                           And more?   \n",
       "312                                           And more?   \n",
       "313                                               More.   \n",
       "111   import streamlit as st\\nimport json\\n\\n\\ndef s...   \n",
       "151   import streamlit as st\\nimport json\\n\\n\\ndef s...   \n",
       "\n",
       "                                                 Answer  TokensOfPrompts  \\\n",
       "7870  Sure, I can certainly help you with that. Here...             31.0   \n",
       "7872  Sure, I can certainly help you with that. Here...              0.0   \n",
       "7898  This Python script is a command-line tool that...            980.0   \n",
       "7906  To get the first 20 rows from a Django model, ...            340.0   \n",
       "7907  Certainly! You can refactor the code to use Dj...            340.0   \n",
       "...                                                 ...              ...   \n",
       "311   Certainly! Here are a few more options for a s...            206.0   \n",
       "312   Certainly! Here are a few more options for a s...            206.0   \n",
       "313   Certainly! Here are a few more options for a s...            206.0   \n",
       "111   The code you provided seems to be a simple bul...            785.0   \n",
       "151   The code you provided seems to be a simple bul...            809.0   \n",
       "\n",
       "      TokensOfAnswers  \n",
       "7870            474.0  \n",
       "7872              0.0  \n",
       "7898            301.0  \n",
       "7906            941.0  \n",
       "7907            941.0  \n",
       "...               ...  \n",
       "311            2636.0  \n",
       "312            2636.0  \n",
       "313            2636.0  \n",
       "111            3270.0  \n",
       "151            7233.0  \n",
       "\n",
       "[460 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate final dataset.\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df_pr2, df_pr3, df_pr4, df_issue2, df_issue3, df_issue4, df_discussion2,\n",
    "        df_discussion3, df_discussion4\n",
    "        ]\n",
    "    )\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1348 entries, 7870 to 313\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   RepoName            1348 non-null   object \n",
      " 1   URL_chatgptsharing  1348 non-null   object \n",
      " 2   Prompt              1348 non-null   object \n",
      " 3   Answer              1348 non-null   object \n",
      " 4   TokensOfPrompts     1348 non-null   float64\n",
      " 5   TokensOfAnswers     1348 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 73.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Merged Dataset to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save to file\n",
    "\n",
    "# df.to_csv(os.path.join(dir_path, \"cleaned\", \"combine.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
