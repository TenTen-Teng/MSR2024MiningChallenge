{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import spacy\n",
    "from multiprocessing.dummy import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = pd.read_csv(\"/Users/teng/UBCO/mds_labs/block4/542/data/DevGPT/cleaned/pr_total.csv\")\n",
    "df_issue = pd.read_csv(\"/Users/teng/UBCO/mds_labs/block4/542/data/DevGPT/cleaned/issue_total.csv\")\n",
    "df_discussion = pd.read_csv(\"/Users/teng/UBCO/mds_labs/block4/542/data/DevGPT/cleaned/discussion_total.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean them up\n",
    "# Remove nan answer and promot.\n",
    "df_pr = df_pr[~df_pr[\"Answer\"].isna()]\n",
    "df_pr = df_pr[~df_pr[\"Prompt\"].isna()]\n",
    "\n",
    "df_issue = df_issue[~df_issue[\"Answer\"].isna()]\n",
    "df_issue = df_issue[~df_issue[\"Prompt\"].isna()]\n",
    "\n",
    "df_discussion = df_discussion[~df_discussion[\"Answer\"].isna()]\n",
    "df_discussion = df_discussion[~df_discussion[\"Prompt\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out Python and English\n",
    "df_pr = df_pr.loc[df_pr[\"RepoLanguage\"] == \"Python\"]\n",
    "df_issue = df_issue.loc[df_issue[\"RepoLanguage\"] == \"Python\"]\n",
    "df_discussion = df_discussion.loc[df_discussion[\"RepoLanguage\"] == \"Python\"]\n",
    "\n",
    "\n",
    "# Detect answer language\n",
    "df_pr[\"Language\"] = df_pr[\"Answer\"].apply(detect)\n",
    "df_issue[\"Language\"] = df_issue[\"Answer\"].apply(detect)\n",
    "df_discussion[\"Language\"] = df_discussion[\"Answer\"].apply(detect)\n",
    "\n",
    "\n",
    "# Get English only.\n",
    "df_pr = df_pr.loc[df_pr[\"Language\"] == \"en\"]\n",
    "df_issue = df_issue.loc[df_issue[\"Language\"] == \"en\"]\n",
    "df_discussion = df_discussion.loc[df_discussion[\"Language\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478\n",
      "287\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(df_pr))\n",
    "print(len(df_issue))\n",
    "print(len(df_discussion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Type', 'URL_pr', 'Author', 'RepoName', 'RepoLanguage',\n",
       "       'Number', 'Title_x', 'Body', 'CreatedAt', 'ClosedAt', 'MergedAt',\n",
       "       'UpdatedAt', 'State', 'Additions', 'Deletions', 'ChangedFiles',\n",
       "       'CommitsTotalCount', 'CommitShas', 'CommitSha', 'source_date',\n",
       "       'URL_chatgptsharing_x', 'Status', 'DateOfConversation', 'DateOfAccess',\n",
       "       'Title_y', 'NumberOfPrompts', 'TokensOfPrompts', 'TokensOfAnswers',\n",
       "       'Model', 'HTMLContent', 'URL_chatgptsharing_y', 'MentionedURL',\n",
       "       'MentionedProperty', 'MentionedAuthor', 'MentionedText',\n",
       "       'MentionedPath', 'URL_chatgptsharing', 'Prompt', 'Answer', 'ListOfCode',\n",
       "       'Language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Type', 'URL_issue', 'Author', 'RepoName', 'RepoLanguage',\n",
       "       'Number', 'Title_x', 'Body', 'CreatedAt', 'ClosedAt', 'UpdatedAt',\n",
       "       'State', 'source_date', 'URL_chatgptsharing_x', 'Status',\n",
       "       'DateOfConversation', 'DateOfAccess', 'Title_y', 'NumberOfPrompts',\n",
       "       'TokensOfPrompts', 'TokensOfAnswers', 'Model', 'HTMLContent',\n",
       "       'URL_chatgptsharing_y', 'MentionedURL', 'MentionedProperty',\n",
       "       'MentionedAuthor', 'MentionedText', 'URL_chatgptsharing', 'Prompt',\n",
       "       'Answer', 'ListOfCode', 'Language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issue.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Type', 'URL_discussion', 'Author', 'RepoName',\n",
       "       'RepoLanguage', 'Number', 'Title_x', 'Body', 'CreatedAt', 'ClosedAt',\n",
       "       'UpdatedAt', 'Closed', 'UpvoteCount', 'source_date',\n",
       "       'URL_chatgptsharing_x', 'Status', 'DateOfConversation', 'DateOfAccess',\n",
       "       'Title_y', 'NumberOfPrompts', 'TokensOfPrompts', 'TokensOfAnswers',\n",
       "       'Model', 'HTMLContent', 'URL_chatgptsharing_y', 'MentionedURL',\n",
       "       'MentionedProperty', 'MentionedAuthor', 'MentionedText',\n",
       "       'MentionedIsAnswer', 'MentionedUpvoteCount', 'URL_chatgptsharing',\n",
       "       'Prompt', 'Answer', 'ListOfCode', 'Language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_discussion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200\n",
      "197 204 204\n",
      "38 39 39\n"
     ]
    }
   ],
   "source": [
    "df_pr2 = df_pr[[\"RepoName\", \"URL_chatgptsharing\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_pr3 = df_pr[[\"RepoName\", \"URL_chatgptsharing_x\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_pr3.rename(columns={\"URL_chatgptsharing_x\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "df_pr4 = df_pr[[\"RepoName\", \"URL_chatgptsharing_y\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_pr4.rename(columns={\"URL_chatgptsharing_y\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_issue2 = df_issue[[\"RepoName\", \"URL_chatgptsharing\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_issue3 = df_issue[[\"RepoName\", \"URL_chatgptsharing_x\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_issue3.rename(columns={\"URL_chatgptsharing_x\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "df_issue4 = df_issue[[\"RepoName\", \"URL_chatgptsharing_y\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_issue4.rename(columns={\"URL_chatgptsharing_y\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "df_discussion2 = df_discussion[[\"RepoName\", \"URL_chatgptsharing\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_discussion3 = df_discussion[[\"RepoName\", \"URL_chatgptsharing_x\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_discussion3.rename(columns={\"URL_chatgptsharing_x\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "df_discussion4 = df_discussion[[\"RepoName\", \"URL_chatgptsharing_y\", \"Prompt\", \"Answer\"]].drop_duplicates()\n",
    "df_discussion4.rename(columns={\"URL_chatgptsharing_y\": \"URL_chatgptsharing\"}, inplace=True)\n",
    "\n",
    "\n",
    "print(len(df_pr2), len(df_pr3), len(df_pr4))\n",
    "print(len(df_issue2), len(df_issue3), len(df_issue4))\n",
    "print(len(df_discussion2), len(df_discussion3), len(df_discussion4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RepoName</th>\n",
       "      <th>URL_chatgptsharing</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>paul-gauthier/aider</td>\n",
       "      <td>https://chat.openai.com/share/4555f0ea-1e7b-49...</td>\n",
       "      <td>How can I setup a github action to automatical...</td>\n",
       "      <td>Sure, I can certainly help you with that. Here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>chitalian/gptask</td>\n",
       "      <td>https://chat.openai.com/share/902cd378-3ebc-4e...</td>\n",
       "      <td>Give me some test commands for this\\n\\nimport ...</td>\n",
       "      <td>This Python script is a command-line tool that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>how to get the first 20 rows from a django model?</td>\n",
       "      <td>To get the first 20 rows from a Django model, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>I have this view for infinite scroll, would be...</td>\n",
       "      <td>Certainly! You can refactor the code to use Dj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>for page 49 this gives:\\n\\nInternal Server Err...</td>\n",
       "      <td>Certainly! To handle the ValueError when conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>Do you have more?</td>\n",
       "      <td>Certainly! Here are a few additional options f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>And more?</td>\n",
       "      <td>Certainly! Here are a few more options for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>And more?</td>\n",
       "      <td>Certainly! Here are a few more options for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>uuid6/prototypes</td>\n",
       "      <td>https://chat.openai.com/share/97dbf284-129f-42...</td>\n",
       "      <td>More.</td>\n",
       "      <td>Certainly! Here are a few more options for a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>sugi-01096/72</td>\n",
       "      <td>https://chat.openai.com/share/e2c50f86-6c14-4f...</td>\n",
       "      <td>import streamlit as st\\nimport json\\n\\n\\ndef s...</td>\n",
       "      <td>The code you provided seems to be a simple bul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>443 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RepoName                                 URL_chatgptsharing  \\\n",
       "7870   paul-gauthier/aider  https://chat.openai.com/share/4555f0ea-1e7b-49...   \n",
       "7898      chitalian/gptask  https://chat.openai.com/share/902cd378-3ebc-4e...   \n",
       "7906  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7907  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7908  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "...                    ...                                                ...   \n",
       "310       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "311       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "312       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "313       uuid6/prototypes  https://chat.openai.com/share/97dbf284-129f-42...   \n",
       "111          sugi-01096/72  https://chat.openai.com/share/e2c50f86-6c14-4f...   \n",
       "\n",
       "                                                 Prompt  \\\n",
       "7870  How can I setup a github action to automatical...   \n",
       "7898  Give me some test commands for this\\n\\nimport ...   \n",
       "7906  how to get the first 20 rows from a django model?   \n",
       "7907  I have this view for infinite scroll, would be...   \n",
       "7908  for page 49 this gives:\\n\\nInternal Server Err...   \n",
       "...                                                 ...   \n",
       "310                                   Do you have more?   \n",
       "311                                           And more?   \n",
       "312                                           And more?   \n",
       "313                                               More.   \n",
       "111   import streamlit as st\\nimport json\\n\\n\\ndef s...   \n",
       "\n",
       "                                                 Answer  \n",
       "7870  Sure, I can certainly help you with that. Here...  \n",
       "7898  This Python script is a command-line tool that...  \n",
       "7906  To get the first 20 rows from a Django model, ...  \n",
       "7907  Certainly! You can refactor the code to use Dj...  \n",
       "7908  Certainly! To handle the ValueError when conve...  \n",
       "...                                                 ...  \n",
       "310   Certainly! Here are a few additional options f...  \n",
       "311   Certainly! Here are a few more options for a s...  \n",
       "312   Certainly! Here are a few more options for a s...  \n",
       "313   Certainly! Here are a few more options for a s...  \n",
       "111   The code you provided seems to be a simple bul...  \n",
       "\n",
       "[443 rows x 4 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        df_pr2, df_pr3, df_pr4, df_issue2, df_issue3, df_issue4, df_discussion2,\n",
    "        df_discussion3, df_discussion4\n",
    "        ]\n",
    "    )\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1321 entries, 7870 to 313\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   RepoName            1321 non-null   object\n",
      " 1   URL_chatgptsharing  1321 non-null   object\n",
      " 2   Prompt              1321 non-null   object\n",
      " 3   Answer              1321 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 51.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/teng/UBCO/mds_labs/block4/542/data/DevGPT/cleaned/combine.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RepoName</th>\n",
       "      <th>URL_chatgptsharing</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>paul-gauthier/aider</td>\n",
       "      <td>https://chat.openai.com/share/4555f0ea-1e7b-49...</td>\n",
       "      <td>How can I setup a github action to automatical...</td>\n",
       "      <td>Sure, I can certainly help you with that. Here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>chitalian/gptask</td>\n",
       "      <td>https://chat.openai.com/share/902cd378-3ebc-4e...</td>\n",
       "      <td>Give me some test commands for this\\n\\nimport ...</td>\n",
       "      <td>This Python script is a command-line tool that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>how to get the first 20 rows from a django model?</td>\n",
       "      <td>To get the first 20 rows from a Django model, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>I have this view for infinite scroll, would be...</td>\n",
       "      <td>Certainly! You can refactor the code to use Dj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>for page 49 this gives:\\n\\nInternal Server Err...</td>\n",
       "      <td>Certainly! To handle the ValueError when conve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RepoName                                 URL_chatgptsharing  \\\n",
       "7870   paul-gauthier/aider  https://chat.openai.com/share/4555f0ea-1e7b-49...   \n",
       "7898      chitalian/gptask  https://chat.openai.com/share/902cd378-3ebc-4e...   \n",
       "7906  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7907  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7908  bbelderbos/htmx-demo  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "\n",
       "                                                 Prompt  \\\n",
       "7870  How can I setup a github action to automatical...   \n",
       "7898  Give me some test commands for this\\n\\nimport ...   \n",
       "7906  how to get the first 20 rows from a django model?   \n",
       "7907  I have this view for infinite scroll, would be...   \n",
       "7908  for page 49 this gives:\\n\\nInternal Server Err...   \n",
       "\n",
       "                                                 Answer  \n",
       "7870  Sure, I can certainly help you with that. Here...  \n",
       "7898  This Python script is a command-line tool that...  \n",
       "7906  To get the first 20 rows from a Django model, ...  \n",
       "7907  Certainly! You can refactor the code to use Dj...  \n",
       "7908  Certainly! To handle the ValueError when conve...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RepoName</th>\n",
       "      <th>URL_chatgptsharing</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7870</th>\n",
       "      <td>paul-gauthier/aider</td>\n",
       "      <td>https://chat.openai.com/share/4555f0ea-1e7b-49...</td>\n",
       "      <td>How can I setup a github action to automatical...</td>\n",
       "      <td>Sure, I can certainly help you with that. Here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>chitalian/gptask</td>\n",
       "      <td>https://chat.openai.com/share/902cd378-3ebc-4e...</td>\n",
       "      <td>Give me some test commands for this\\n\\nimport ...</td>\n",
       "      <td>This Python script is a command-line tool that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>how to get the first 20 rows from a django model?</td>\n",
       "      <td>To get the first 20 rows from a Django model, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>I have this view for infinite scroll, would be...</td>\n",
       "      <td>Certainly! You can refactor the code to use Dj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>bbelderbos/htmx-demo</td>\n",
       "      <td>https://chat.openai.com/share/c8c101fa-aaae-49...</td>\n",
       "      <td>for page 49 this gives:\\n\\nInternal Server Err...</td>\n",
       "      <td>Certainly! To handle the ValueError when conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>HaroldMitts/VoAIce</td>\n",
       "      <td>https://chat.openai.com/share/262e8d7d-657b-4a...</td>\n",
       "      <td>output audio of the following sentence;\\n\\n\"Do...</td>\n",
       "      <td>Sure, here is the audio version of your text:C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>sugi-01096/72</td>\n",
       "      <td>https://chat.openai.com/share/e2c50f86-6c14-4f...</td>\n",
       "      <td>import streamlit as st\\nimport json\\n\\n\\ndef s...</td>\n",
       "      <td>The code you provided seems to be a simple bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sugi-01096/72</td>\n",
       "      <td>https://chat.openai.com/share/4cd4bb4a-56f9-4a...</td>\n",
       "      <td>import streamlit as st\\nimport json\\n\\n\\ndef s...</td>\n",
       "      <td>The code you provided seems to be a simple bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Significant-Gravitas/Auto-GPT</td>\n",
       "      <td>https://chat.openai.com/share/aec2922e-dbcc-47...</td>\n",
       "      <td>I am using venv(python module env) on the mac ...</td>\n",
       "      <td>To upgrade the Python version within a virtual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>HaroldMitts/VoAIce</td>\n",
       "      <td>https://chat.openai.com/share/262e8d7d-657b-4a...</td>\n",
       "      <td>output audio of the following sentence;\\n\\n\"Do...</td>\n",
       "      <td>Sure, here is the audio version of your text:C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           RepoName  \\\n",
       "7870            paul-gauthier/aider   \n",
       "7898               chitalian/gptask   \n",
       "7906           bbelderbos/htmx-demo   \n",
       "7907           bbelderbos/htmx-demo   \n",
       "7908           bbelderbos/htmx-demo   \n",
       "...                             ...   \n",
       "227              HaroldMitts/VoAIce   \n",
       "111                   sugi-01096/72   \n",
       "131                   sugi-01096/72   \n",
       "186   Significant-Gravitas/Auto-GPT   \n",
       "227              HaroldMitts/VoAIce   \n",
       "\n",
       "                                     URL_chatgptsharing  \\\n",
       "7870  https://chat.openai.com/share/4555f0ea-1e7b-49...   \n",
       "7898  https://chat.openai.com/share/902cd378-3ebc-4e...   \n",
       "7906  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7907  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "7908  https://chat.openai.com/share/c8c101fa-aaae-49...   \n",
       "...                                                 ...   \n",
       "227   https://chat.openai.com/share/262e8d7d-657b-4a...   \n",
       "111   https://chat.openai.com/share/e2c50f86-6c14-4f...   \n",
       "131   https://chat.openai.com/share/4cd4bb4a-56f9-4a...   \n",
       "186   https://chat.openai.com/share/aec2922e-dbcc-47...   \n",
       "227   https://chat.openai.com/share/262e8d7d-657b-4a...   \n",
       "\n",
       "                                                 Prompt  \\\n",
       "7870  How can I setup a github action to automatical...   \n",
       "7898  Give me some test commands for this\\n\\nimport ...   \n",
       "7906  how to get the first 20 rows from a django model?   \n",
       "7907  I have this view for infinite scroll, would be...   \n",
       "7908  for page 49 this gives:\\n\\nInternal Server Err...   \n",
       "...                                                 ...   \n",
       "227   output audio of the following sentence;\\n\\n\"Do...   \n",
       "111   import streamlit as st\\nimport json\\n\\n\\ndef s...   \n",
       "131   import streamlit as st\\nimport json\\n\\n\\ndef s...   \n",
       "186   I am using venv(python module env) on the mac ...   \n",
       "227   output audio of the following sentence;\\n\\n\"Do...   \n",
       "\n",
       "                                                 Answer  \n",
       "7870  Sure, I can certainly help you with that. Here...  \n",
       "7898  This Python script is a command-line tool that...  \n",
       "7906  To get the first 20 rows from a Django model, ...  \n",
       "7907  Certainly! You can refactor the code to use Dj...  \n",
       "7908  Certainly! To handle the ValueError when conve...  \n",
       "...                                                 ...  \n",
       "227   Sure, here is the audio version of your text:C...  \n",
       "111   The code you provided seems to be a simple bul...  \n",
       "131   The code you provided seems to be a simple bul...  \n",
       "186   To upgrade the Python version within a virtual...  \n",
       "227   Sure, here is the audio version of your text:C...  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repo = df.groupby(by=[\"RepoName\"])\n",
    "df_repo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_repo[\"RepoName\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average interactions per pr: 20.015151515151516\n",
      "Maximum number of interactions: 501\n",
      "Minimum number of iteractions: 3\n"
     ]
    }
   ],
   "source": [
    "# Mean number of interactions per issuedf_url\n",
    "ls_url_chatgptsharing = [len(ls) for ls in df_repo.aggregate(list)[\"URL_chatgptsharing\"]]\n",
    "idx_max = np.argmax(ls_url_chatgptsharing)\n",
    "idx_min = np.argmin(ls_url_chatgptsharing)\n",
    "print(\n",
    "    f\"Average interactions per pr: {np.mean(ls_url_chatgptsharing)}\\n\"\n",
    "    f\"Maximum number of interactions: {ls_url_chatgptsharing[idx_max]}\\n\"\n",
    "    f\"Minimum number of iteractions: {ls_url_chatgptsharing[idx_min]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RepoName', 'URL_chatgptsharing'], dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_repo_count = df_repo[\"URL_chatgptsharing\"].aggregate(len).reset_index()\n",
    "df_repo_count.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e8b20d2c543f496b8e13739672c2eec9.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e8b20d2c543f496b8e13739672c2eec9.vega-embed details,\n",
       "  #altair-viz-e8b20d2c543f496b8e13739672c2eec9.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e8b20d2c543f496b8e13739672c2eec9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e8b20d2c543f496b8e13739672c2eec9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e8b20d2c543f496b8e13739672c2eec9\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-fc59c76eb04d6aaab4f4b585e3b3712d\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"field\": \"URL_chatgptsharing\", \"title\": \"Number of Interactions with ChatGPT\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-fc59c76eb04d6aaab4f4b585e3b3712d\": [{\"RepoName\": \"ActivityWatch/aw-server\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"AndyGrant/OpenBench\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"AntonOsika/gpt-engineer\", \"URL_chatgptsharing\": 54}, {\"RepoName\": \"D3Zyre/Copy-All-Files-From-Folder\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"Delgan/loguru\", \"URL_chatgptsharing\": 9}, {\"RepoName\": \"Elucidation/mapf-multiagent-robot-planning\", \"URL_chatgptsharing\": 18}, {\"RepoName\": \"Email-Generation/email_generation\", \"URL_chatgptsharing\": 501}, {\"RepoName\": \"GreyDGL/PentestGPT\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"HaroldMitts/VoAIce\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"Hochfrequenz/kohlrahbi\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"MauriceLe/PIMS\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"NA-MIC/ProjectWeek\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"OpenAdaptAI/OpenAdapt\", \"URL_chatgptsharing\": 38}, {\"RepoName\": \"PromtEngineer/localGPT\", \"URL_chatgptsharing\": 39}, {\"RepoName\": \"RND247/Pype-Synthetic-Data-for-Testing\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"SafEight/wdm-project\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"Shreya-R-Dixit-Memorial-Foundation/EyeDaV2\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"Significant-Gravitas/Auto-GPT\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"SuffolkLITLab/docassemble-ALToolbox\", \"URL_chatgptsharing\": 9}, {\"RepoName\": \"aahnik/temple-web\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"aiplanethub/genai-stack\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"app-sre/qontract-reconcile\", \"URL_chatgptsharing\": 15}, {\"RepoName\": \"bancaditalia/black-it\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"bbelderbos/htmx-demo\", \"URL_chatgptsharing\": 9}, {\"RepoName\": \"chitalian/gptask\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"comfyanonymous/ComfyUI\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"davidusb-geek/emhass\", \"URL_chatgptsharing\": 9}, {\"RepoName\": \"dobbelina/repository.dobbelina\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"dtch1997/gpt-text-gym\", \"URL_chatgptsharing\": 33}, {\"RepoName\": \"embedchain/embedchain\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"gorillamania/AICodeBot\", \"URL_chatgptsharing\": 30}, {\"RepoName\": \"icecube/pisa\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"internetarchive/openlibrary\", \"URL_chatgptsharing\": 9}, {\"RepoName\": \"jasonacox/Powerwall-Dashboard\", \"URL_chatgptsharing\": 18}, {\"RepoName\": \"jefftriplett/frontmatter-cli\", \"URL_chatgptsharing\": 18}, {\"RepoName\": \"karpathy/ng-video-lecture\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"kroitor/asciichart\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"kukulich/home-assistant-jablotron100\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"langchain-ai/langchain\", \"URL_chatgptsharing\": 21}, {\"RepoName\": \"livingbio/gpt-fn\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"meltyyyyy/ICR-2023\", \"URL_chatgptsharing\": 18}, {\"RepoName\": \"mesonbuild/meson\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"metaphorsystems/metaphor-python\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"microsoft/visionmetrics\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"monarch-initiative/oai-monarch-plugin\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"mpoon/gpt-repository-loader\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"mprib/pyxy3d\", \"URL_chatgptsharing\": 18}, {\"RepoName\": \"nuhmanpk/Webtrench\", \"URL_chatgptsharing\": 12}, {\"RepoName\": \"omegaui/linux-voice-control\", \"URL_chatgptsharing\": 33}, {\"RepoName\": \"paul-gauthier/aider\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"related-sciences/nxontology-ml\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"roslinmahmud/easy-hire-backend\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"simonw/asgi-proxy-lib\", \"URL_chatgptsharing\": 30}, {\"RepoName\": \"simonw/datasette-render-markdown\", \"URL_chatgptsharing\": 27}, {\"RepoName\": \"simonw/llm-replicate\", \"URL_chatgptsharing\": 6}, {\"RepoName\": \"simonw/sqlite-utils\", \"URL_chatgptsharing\": 18}, {\"RepoName\": \"simonw/symbex\", \"URL_chatgptsharing\": 30}, {\"RepoName\": \"simonw/ttok\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"sugi-01096/72\", \"URL_chatgptsharing\": 5}, {\"RepoName\": \"teremterem/botmerger\", \"URL_chatgptsharing\": 9}, {\"RepoName\": \"theonlysam/blackjack\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"tinygrad/tinygrad\", \"URL_chatgptsharing\": 15}, {\"RepoName\": \"udayhello/handwritten1\", \"URL_chatgptsharing\": 72}, {\"RepoName\": \"uuid6/prototypes\", \"URL_chatgptsharing\": 60}, {\"RepoName\": \"wafflestudio/wacruit-server\", \"URL_chatgptsharing\": 3}, {\"RepoName\": \"welfare-state-analytics/riksdagen-corpus\", \"URL_chatgptsharing\": 9}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking histogarm\n",
    "# df_url_count.hist(column=\"URL_chatgptsharing\")\n",
    "alt.Chart(df_repo_count).mark_bar().encode(\n",
    "    x=alt.X(\"URL_chatgptsharing:N\", title=\"Number of Interactions with ChatGPT\"),\n",
    "    y=\"count()\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average length of Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = df[\"Prompt\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 586019.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "with Pool() as pool:\n",
    "    doc = pool.map(nlp, tqdm(prompts, total=len(prompts)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 48640.86it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for d in tqdm(doc):\n",
    "    token_without_punc = [token for token in d if not token.is_punct]\n",
    "    tokens.append(token_without_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of prompt per pr: 67.9225352112676\n",
      "---------------------------\n",
      "Maximum length of prompt: ---------------------------------------------------------------------------\n",
      "InvalidArgumentError                      Traceback (most recent call last)\n",
      "<ipython-input-33-22ef21b7d160> in <cell line: 10>()\n",
      "      8 \n",
      "      9 # Now, you can use the model for prediction\n",
      "---> 10 prediction = model.predict(img_expanded)\n",
      "     11 print(f\"This digit is probably a {np.argmax(prediction)}\")\n",
      "     12 \n",
      "\n",
      "1 frames\n",
      "/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n",
      "     50   try:\n",
      "     51     ctx.ensure_initialized()\n",
      "---> 52     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "     53                                         inputs, attrs, num_outputs)\n",
      "     54   except core._NotOkStatusException as e:\n",
      "\n",
      "InvalidArgumentError: Graph execution error:\n",
      "\n",
      "Detected at node 'sequential/conv2d/BiasAdd' defined at (most recent call last):\n",
      "    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "      app.start()\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 600, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1896, in _run_once\n",
      "      handle._run()\n",
      "    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
      "      lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
      "      ret = callback()\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
      "      self.ctx_run(self.run)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
      "      yielded = self.gen.send(value)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
      "      yield gen.maybe_future(dispatch(*args))\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "      yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
      "      self.do_execute(\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "      res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "      if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-31-d9e8d8257638>\", line 3, in <cell line: 3>\n",
      "      prediction = model.predict(img)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2382, in predict\n",
      "      tmp_batch_outputs = self.predict_function(iterator)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step\n",
      "      outputs = model.predict_step(data)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n",
      "      return self(x, training=False)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n",
      "      return super().call(inputs, training=training, mask=mask)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/convolutional/base_conv.py\", line 311, in call\n",
      "      outputs = tf.nn.bias_add(\n",
      "Node: 'sequential/conv2d/BiasAdd'\n",
      "convolution input must be 4-dimensional: [1,28,28]\n",
      "\t [[{{node sequential/conv2d/BiasAdd}}]] [Op:__inference_predict_function_27969]\n",
      "---------------------------\n",
      "Minimum length of prompt: hey\n"
     ]
    }
   ],
   "source": [
    "# Calculate average length of prompt\n",
    "ls_len_promot = [len(token) for token in tokens]\n",
    "idx_max = np.argmax(ls_len_promot)\n",
    "idx_min = np.argmin(ls_len_promot)\n",
    "print(\n",
    "    f\"Average length of prompt per pr: {np.mean(ls_len_promot)}\\n\"\n",
    "    f\"---------------------------\\n\"\n",
    "    f\"Maximum length of prompt: {prompts[idx_max]}\\n\"\n",
    "    f\"---------------------------\\n\"\n",
    "    f\"Minimum length of prompt: {prompts[idx_min]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average length of Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = df[\"Answer\"].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 50554.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "with Pool() as pool:\n",
    "    doc = pool.map(nlp, tqdm(answers, total=len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 25712.62it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "for d in tqdm(doc):\n",
    "    token_without_punc = [token for token in d if not token.is_punct]\n",
    "    tokens.append(token_without_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of answer per pr: 179.38337182448038\n",
      "---------------------------\n",
      "Maximum length of answer: Certainly! Here's an elaboration on the actions mentioned in the Windows response, providing more details about each mouse click and key press:Navigating the GUI:Left-clicking:Single left-click: Pressing the left mouse button once to select or activate an element, such as buttons, checkboxes, links, or menu items.Right-clicking:Single right-click: Pressing the right mouse button once to open a context menu, displaying additional options specific to the clicked item.Double-clicking:Double left-click: Rapidly pressing the left mouse button twice, with a short interval between clicks, to open files, launch applications, or perform actions associated with the clicked item.Middle-clicking:Single middle-click: Pressing the middle mouse button (usually the scroll wheel) once, typically used to open links in new tabs in web browsers or close tabs.Hovering:Moving the mouse cursor over an element without clicking to trigger hover effects, display tooltips, or preview information associated with the element.Basic interactions:Opening/closing windows:Launching applications:Clicking the Start button in the bottom-left corner of the screen to open the Start menu.Navigating through the Start menu to locate and select the desired application icon.Left-clicking on the application icon to launch the application, which opens a new window.Closing windows:Left-clicking on the \"X\" button located in the top-right corner of the window using the mouse cursor to close the active window.Alternatively, pressing the Alt key and while holding it, pressing the F4 key on the keyboard to close the active window.Minimizing/maximizing/restoring windows:Minimizing: Left-clicking on the \"-\" button located in the top-left corner of the window to minimize the active window.Maximizing/Restoring: Left-clicking on the green \"+\" button located in the top-left corner of the window to toggle between maximizing and restoring the window's size.Switching between open windows:Pressing and holding the Alt key on the keyboard and then pressing the Tab key to cycle through the open windows.Releasing the Alt key when the desired window is highlighted to switch to that window.Managing files:Creating files/folders:Opening a file explorer window, such as Windows Explorer or File Explorer, by double-clicking its icon on the desktop or selecting it from the Start menu.Navigating to the desired location where the file or folder should be created.Right-clicking in the file explorer window and selecting \"New\" from the context menu.Choosing the desired file type or folder option from the submenu to create the respective item.Providing a name for the file or folder by typing it using the keyboard and pressing Enter to confirm.Opening files/folders:Opening a file explorer window, such as Windows Explorer or File Explorer, by double-clicking its icon on the desktop or selecting it from the Start menu.Navigating to the location where the file or folder is located.Left-clicking on the file or folder icon in the file explorer window to open it.Saving files:Using an application that allows saving files, such as a text editor or image editor.Clicking the \"File\" menu located in the application's menu bar at the top of the screen.Selecting the \"Save\" or \"Save As\" option from the dropdown menu.If \"Save As\" is chosen, specifying the desired location and providing a file name in the file explorer window that appears.Clicking the \"Save\" button in the file explorer window or pressing Enter to save the file.Deleting files/folders:Opening a file explorer window, such as Windows Explorer or File Explorer, by double-clicking its icon on the desktop or selecting it from the Start menu.Navigating to the location where the file or folder is located.Selecting the file(s) or folder(s) to be deleted by left-clicking on them in the file explorer window.Right-clicking on the selected file(s) or folder(s) to open the context menu.Choosing the \"Delete\" option from the context menu to move the selected item(s) to the Recycle Bin.Copying/cutting/pasting:Copying:Selecting the item(s) to be copied by left-clicking and dragging the mouse cursor over them to create a selection area or by holding the Shift key and left-clicking on individual items to select them.Right-clicking on the selected item(s) to open the context menu.Choosing the \"Copy\" option from the context menu to copy the selected item(s) to the clipboard.Cutting:Selecting the item(s) to be cut by left-clicking and dragging the mouse cursor over them to create a selection area or by holding the Shift key and left-clicking on individual items to select them.Right-clicking on the selected item(s) to open the context menu.Choosing the \"Cut\" option from the context menu to cut the selected item(s), which moves them to the clipboard.Pasting:Navigating to the desired location where the copied or cut item(s) should be pasted.Right-clicking in the destination location to open the context menu.Choosing the \"Paste\" option from the context menu to paste the item(s) from the clipboard to the selected location.Application-specific tasks:Operating specific software:Editing images:Launching an image editing software like Adobe Photoshop or Paint.Opening the desired image file using the software's \"Open\" option from the \"File\" menu or toolbar.Using various tools and options available in the software, such as selecting regions, applying filters, adjusting colors, or adding text, by clicking on the corresponding buttons or menu items.Saving the edited image using the software's \"Save\" or \"Save As\" option from the \"File\" menu or toolbar.Writing code:Launching an integrated development environment (IDE) like Microsoft Visual Studio or JetBrains IntelliJ IDEA.Creating a new project or opening an existing project using the IDE's menus or toolbar.Opening the code editor within the IDE by selecting the desired file or creating a new file.Typing or modifying code using the keyboard.Using keyboard shortcuts or menu options to compile, run, or debug the code.Composing emails:Launching an email client like Microsoft Outlook or Mozilla Thunderbird.Clicking the \"New Email\" button in the toolbar or selecting the \"New Email\" option from the \"File\" menu.Entering the recipient(s), subject, and message in the designated fields.Clicking the \"Send\" button in the toolbar or selecting the \"Send\" option from the \"File\" menu to send the email.Please note that this list provides a general description of common actions, and the exact steps may vary slightly depending on the specific applications and their versions.\n",
      "---------------------------\n",
      "Minimum length of answer: id|precision\n",
      "MONDO:0014498|high\n",
      "EFO:0009011|medium\n",
      "MONDO:0024239|low\n"
     ]
    }
   ],
   "source": [
    "# Calculate average length of prompt\n",
    "ls_len_answer = [len(token) for token in tokens]\n",
    "idx_max = np.argmax(ls_len_answer)\n",
    "idx_min = np.argmin(ls_len_answer)\n",
    "print(\n",
    "    f\"Average length of answer per pr: {np.mean(ls_len_answer)}\\n\"\n",
    "    f\"---------------------------\\n\"\n",
    "    f\"Maximum length of answer: {answers[idx_max]}\\n\"\n",
    "    f\"---------------------------\\n\"\n",
    "    f\"Minimum length of answer: {answers[idx_min]}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
